{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eih7Cvguk8yd"
      },
      "source": [
        "# Model Evaluation Notebook## Comprehensive Performance Metrics for V1 and V2 ModelsThis notebook evaluates all trained models (V1 and V2) and generates complete performance statistics including:- **Accuracy**: Overall classification correctness- **Precision**: Positive prediction accuracy- **Recall**: True positive detection rate- **F1-Score**: Harmonic mean of precision and recall- **ROC-AUC**: Area under the ROC curve- **KS Statistic**: Kolmogorov-Smirnov test statistic### Model Inventory- **V1 Models (5)**: Logistic Regression, Random Forest, XGBoost, LightGBM, CatBoost- **V2 Models (15)**: 3 feature sets × 5 algorithms### Feature Sets- **V1**: 12 traditional features- **V2 Feature Set A**: 4 composite scores only- **V2 Feature Set B**: 4 composite scores + 4 key categoricals (8 features)- **V2 Feature Set C**: 4 composite scores + 6 categoricals (10 features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TVTT4xxk8ye"
      },
      "source": [
        "## Section 1: Imports and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-OoOh93k8yf"
      },
      "outputs": [],
      "source": [
        "# Core librariesimport pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as snsimport warningsimport osfrom math import pi# Preprocessingfrom sklearn.model_selection import train_test_splitfrom sklearn.preprocessing import LabelEncoder, StandardScalerfrom imblearn.over_sampling import SMOTE# Modelsfrom sklearn.linear_model import LogisticRegressionfrom sklearn.ensemble import RandomForestClassifierfrom xgboost import XGBClassifierfrom lightgbm import LGBMClassifierfrom catboost import CatBoostClassifier# Evaluation metricsfrom sklearn.metrics import (    accuracy_score, precision_score, recall_score, f1_score,    roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay)from scipy import stats# Configurationwarnings.filterwarnings('ignore')plt.style.use('seaborn-v0_8-darkgrid')sns.set_palette(\"husl\")# ConstantsRANDOM_STATE = 42TARGET = 'Defaulted'DATA_PATH = '../Github Original Data.csv'print(\"✓ All libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N-3Dipbk8yg"
      },
      "source": [
        "## Section 2: Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVsowW-ik8yh"
      },
      "outputs": [],
      "source": [
        "# Load the dataset (same as used in training)df = pd.read_csv(DATA_PATH, encoding='latin-1')print(f\"Dataset shape: {df.shape}\")print(f\"\\nTarget variable '{TARGET}' distribution:\")print(df[TARGET].value_counts())print(f\"\\nDefault rate: {df[TARGET].mean()*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSPOFoEZk8yh"
      },
      "source": [
        "## Section 3: Feature Definitions### V1 Features (12 features)Traditional features from initial modeling approach.### V2 Feature Sets- **Feature Set A**: Composite scores only (4 features)- **Feature Set B**: Composite + key categoricals (8 features)- **Feature Set C**: Extended feature set (10 features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeDqa57vk8yh"
      },
      "outputs": [],
      "source": [
        "# V1 Model Features (12 features)V1_FEATURES = [    'Extra Income Brackets',    'Categorize Rent Payment',    'School Fees Categorical',    'Age Group',    'Education',    'Loan Access',  # Prior Loan Access    'CRB Class',    'Logic on Income',  # Income Diversity    'Categorizing Utility Expenses',    'Expense Relative to Income',    'Affordability (HH)',    'Living']# V2 Feature Sets# Feature Set A: Composite Scores Only (4 features)FEATURES_A = [    'Financial_Resilience_Score',    'Business_Quality_Score',    'Stability_Score',    'Expense_Management_Score']# Feature Set B: Composite + Key Categoricals (8 features)FEATURES_B = [    'Financial_Resilience_Score',    'Business_Quality_Score',    'Stability_Score',    'Expense_Management_Score',    'Age Group',    'Education',    'CRB Class',    'Living']# Feature Set C: Extended (10 features, no Prior Loan)FEATURES_C = [    'Financial_Resilience_Score',    'Business_Quality_Score',    'Stability_Score',    'Expense_Management_Score',    'Age Group',    'Education',    'CRB Class',    'Living',    'Logic on Income',    'Marital status']print(\"Feature sets defined:\")print(f\"  V1 Features: {len(V1_FEATURES)} features\")print(f\"  Feature Set A: {len(FEATURES_A)} features\")print(f\"  Feature Set B: {len(FEATURES_B)} features\")print(f\"  Feature Set C: {len(FEATURES_C)} features\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3OrR9hjk8yi"
      },
      "source": [
        "## Section 4: Composite Score Generation (for V2 Models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yL8vaJOuk8yi"
      },
      "outputs": [],
      "source": [
        "def calculate_financial_resilience(row):\n",
        "    \"\"\"\n",
        "    Financial Resilience Score (0-100)\n",
        "    Weights: Extra Income (35%), Expense Ratio (30%), Income Diversity (20%), Savings (15%)\n",
        "    \"\"\"\n",
        "    score = 0\n",
        "\n",
        "    # Extra Income Level (35% weight)\n",
        "    extra_income = str(row.get('Extra_Income_Brackets', '')).lower()\n",
        "    if 'moderate' in extra_income or 'high' in extra_income:\n",
        "        score += 35 * 1.0\n",
        "    elif 'low' in extra_income and 'no' not in extra_income:\n",
        "        score += 35 * 0.3\n",
        "    else:\n",
        "        score += 35 * 0.6\n",
        "\n",
        "    # Expense-to-Income Ratio (30% weight)\n",
        "    expense_ratio = str(row.get('Expense_Ratio', '')).lower()\n",
        "    if '1/3' in expense_ratio:\n",
        "        score += 30 * 1.0\n",
        "    elif 'half' in expense_ratio:\n",
        "        score += 30 * 0.7\n",
        "    elif '2/3' in expense_ratio and 'more' not in expense_ratio:\n",
        "        score += 30 * 0.4\n",
        "    else:\n",
        "        score += 30 * 0.5\n",
        "\n",
        "    # Income Diversity (20% weight)\n",
        "    income_div = str(row.get('Income_Diversity', '')).lower()\n",
        "    if 'full' in income_div:\n",
        "        score += 20 * 1.0\n",
        "    elif 'regular' in income_div:\n",
        "        score += 20 * 0.7\n",
        "    elif 'extra' in income_div:\n",
        "        score += 20 * 0.5\n",
        "    else:\n",
        "        score += 20 * 0.6\n",
        "\n",
        "    # Savings Level (15% weight)\n",
        "    savings = str(row.get('Savings_Category', '')).lower()\n",
        "    if 'high' in savings:\n",
        "        score += 15 * 1.0\n",
        "    elif 'low' in savings and 'no' not in savings:\n",
        "        score += 15 * 0.8\n",
        "    else:\n",
        "        score += 15 * 0.6\n",
        "\n",
        "    return score\n",
        "\n",
        "def calculate_business_quality(row):\n",
        "    \"\"\"\n",
        "    Business Quality Score (0-100)\n",
        "    Weights: Rent (45%), Utility (30%), Business Affordability (25%)\n",
        "    \"\"\"\n",
        "    score = 0\n",
        "\n",
        "    # Rent Payment Level (45% weight)\n",
        "    rent = str(row.get('Rent_Category', '')).lower()\n",
        "    if 'high' in rent:\n",
        "        score += 45 * 1.0\n",
        "    elif 'low' in rent and 'no' not in rent:\n",
        "        score += 45 * 0.5\n",
        "    else:\n",
        "        score += 45 * 0.6\n",
        "\n",
        "    # Utility Expenses (30% weight)\n",
        "    utility = str(row.get('Utility_Category', '')).lower()\n",
        "    if 'high' in utility:\n",
        "        score += 30 * 1.0\n",
        "    elif 'low' in utility and 'no' not in utility:\n",
        "        score += 30 * 0.5\n",
        "    else:\n",
        "        score += 30 * 0.7\n",
        "\n",
        "    # Business Affordability (25% weight)\n",
        "    afford = str(row.get('Affordability_Business', '')).lower()\n",
        "    if 'profitable' in afford:\n",
        "        score += 25 * 1.0\n",
        "    else:\n",
        "        score += 25 * 0.5\n",
        "\n",
        "    return score\n",
        "\n",
        "def calculate_stability(row):\n",
        "    \"\"\"\n",
        "    Stability Score (0-100)\n",
        "    Weights: School Fees (40%), Regular Income (30%), Income Streams (30%)\n",
        "    \"\"\"\n",
        "    score = 0\n",
        "\n",
        "    # School Fees Commitment (40% weight)\n",
        "    school = str(row.get('SchoolFees_Category', '')).lower()\n",
        "    if 'high' in school:\n",
        "        score += 40 * 1.0\n",
        "    elif 'low' in school and 'no' not in school:\n",
        "        score += 40 * 0.5\n",
        "    else:\n",
        "        score += 40 * 0.9\n",
        "\n",
        "    # Regular Income Presence (30% weight)\n",
        "    regular = str(row.get('Regular_Income_Brackets', '')).lower()\n",
        "    if 'moderate' in regular or 'high' in regular:\n",
        "        score += 30 * 1.0\n",
        "    elif 'low' in regular and 'no' not in regular:\n",
        "        score += 30 * 1.1\n",
        "    else:\n",
        "        score += 30 * 0.85\n",
        "\n",
        "    # Multiple Income Streams (30% weight)\n",
        "    income_div = str(row.get('Income_Diversity', '')).lower()\n",
        "    if 'full' in income_div:\n",
        "        score += 30 * 1.0\n",
        "    elif 'regular' in income_div:\n",
        "        score += 30 * 0.8\n",
        "    elif 'extra' in income_div:\n",
        "        score += 30 * 0.6\n",
        "    else:\n",
        "        score += 30 * 0.7\n",
        "\n",
        "    return min(score, 100)\n",
        "\n",
        "def calculate_expense_management(row):\n",
        "    \"\"\"\n",
        "    Expense Management Score (0-100)\n",
        "    Weights: Expense Ratio (50%), Affordability HH (35%), Utility (15%)\n",
        "    \"\"\"\n",
        "    score = 0\n",
        "\n",
        "    # Expense Relative to Income (50% weight)\n",
        "    expense_ratio = str(row.get('Expense_Ratio', '')).lower()\n",
        "    if '1/3' in expense_ratio:\n",
        "        score += 50 * 1.0\n",
        "    elif 'half' in expense_ratio:\n",
        "        score += 50 * 0.7\n",
        "    elif '2/3' in expense_ratio and 'more' not in expense_ratio:\n",
        "        score += 50 * 0.4\n",
        "    else:\n",
        "        score += 50 * 0.5\n",
        "\n",
        "    # Affordability HH (35% weight)\n",
        "    afford = str(row.get('Affordability_HH', '')).lower()\n",
        "    if 'profitable' in afford:\n",
        "        score += 35 * 1.0\n",
        "    else:\n",
        "        score += 35 * 0.5\n",
        "\n",
        "    # Utility Expenses (15% weight)\n",
        "    utility = str(row.get('Utility_Category', '')).lower()\n",
        "    if 'high' in utility:\n",
        "        score += 15 * 1.0\n",
        "    elif 'low' in utility and 'no' not in utility:\n",
        "        score += 15 * 0.5\n",
        "    else:\n",
        "        score += 15 * 0.7\n",
        "\n",
        "    return score\n",
        "\n",
        "print(\"✓ Composite score functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP6o69jdk8yj"
      },
      "source": [
        "## Section 5: Prepare Intermediate Features for Composite Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOwWLtGEk8yj"
      },
      "outputs": [],
      "source": [
        "# Generate intermediate features needed for composite score calculations# These ensure consistent naming across all score functions# Affordability Businessif \"Affordability\" in df.columns:    df[\"Affordability_Business\"] = df[\"Affordability\"].fillna(\"Unknown\")else:    df[\"Affordability_Business\"] = \"Unknown\"# Affordability HH (Household)if \"Affordability (HH)\" in df.columns:    df[\"Affordability_HH\"] = df[\"Affordability (HH)\"].fillna(\"Unknown\")else:    df[\"Affordability_HH\"] = df.get(\"Affordability_Business\", \"Unknown\")# Extra Income Bracketsif \"Extra Income Brackets\" in df.columns:    df[\"Extra_Income_Brackets\"] = df[\"Extra Income Brackets\"].fillna(\"No Extra Income\")else:    extra_income = pd.to_numeric(df.get(\"Extra Income\", 0), errors=\"coerce\").fillna(0)    df[\"Extra_Income_Brackets\"] = np.where(        extra_income == 0, \"No Extra Income\",        np.where(extra_income < 5000, \"Low Extra Income\",        np.where(extra_income < 10000, \"Moderate Extra Income\", \"High Extra Income\"))    )# Expense Ratioif \"Expense Relative to Income\" in df.columns:    df[\"Expense_Ratio\"] = df[\"Expense Relative to Income\"].fillna(\"Unknown\")else:    df[\"Expense_Ratio\"] = \"Unknown\"# Income Diversityif \"Logic on Income\" in df.columns:    df[\"Income_Diversity\"] = df[\"Logic on Income\"].fillna(\"Unknown\")else:    df[\"Income_Diversity\"] = \"Unknown\"# Savings Categoryif \"Savings\" in df.columns:    df[\"Savings_Category\"] = df[\"Savings\"].fillna(\"No Savings\")else:    df[\"Savings_Category\"] = \"No Savings\"# Rent Categoryif \"Categorize Rent Payment\" in df.columns:    df[\"Rent_Category\"] = df[\"Categorize Rent Payment\"].fillna(\"No Rent\")else:    df[\"Rent_Category\"] = \"No Rent\"# Utility Categoryif \"Categorizing Utility Expenses\" in df.columns:    df[\"Utility_Category\"] = df[\"Categorizing Utility Expenses\"].fillna(\"None\")else:    df[\"Utility_Category\"] = \"None\"# School Fees Categoryif \"School Fees Categorical\" in df.columns:    df[\"SchoolFees_Category\"] = df[\"School Fees Categorical\"].fillna(\"None\")else:    df[\"SchoolFees_Category\"] = \"None\"# Regular Income Bracketsif \"Regular Income\" in df.columns:    regular_income = pd.to_numeric(df[\"Regular Income\"], errors=\"coerce\").fillna(0)    df[\"Regular_Income_Brackets\"] = np.where(        regular_income == 0, \"No Regular Income\",        np.where(regular_income < 10000, \"Low Regular Income\",        np.where(regular_income < 20000, \"Moderate Regular Income\", \"High Regular Income\"))    )else:    df[\"Regular_Income_Brackets\"] = \"Unknown\"print(\"✓ Intermediate features prepared\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kjxiZfGk8yk"
      },
      "source": [
        "## Section 6: Generate Composite Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XAr0ggpk8yk"
      },
      "outputs": [],
      "source": [
        "# Generate the 4 composite scoresdf[\"Financial_Resilience_Score\"] = df.apply(calculate_financial_resilience, axis=1)df[\"Business_Quality_Score\"] = df.apply(calculate_business_quality, axis=1)df[\"Stability_Score\"] = df.apply(calculate_stability, axis=1)df[\"Expense_Management_Score\"] = df.apply(calculate_expense_management, axis=1)print(\"Composite Scores Generated:\")print(\"=\" * 60)composite_cols = [\"Financial_Resilience_Score\", \"Business_Quality_Score\",                   \"Stability_Score\", \"Expense_Management_Score\"]for col in composite_cols:    print(f\"\\n{col}:\")    print(f\"  Mean: {df[col].mean():.2f}\")    print(f\"  Std:  {df[col].std():.2f}\")    print(f\"  Min:  {df[col].min():.2f}\")    print(f\"  Max:  {df[col].max():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc0d-N8Ck8yk"
      },
      "source": [
        "## Section 7: Data Preprocessing and Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pgh5fw6-k8yk"
      },
      "outputs": [],
      "source": [
        "def prepare_data(df, features, target, test_size=0.15, val_size=0.15):    \"\"\"    Prepare data for a specific feature set.    Returns: X_train, X_val, X_test, y_train, y_val, y_test, encoders, scaler    \"\"\"    # Create working dataframe    available_features = [f for f in features if f in df.columns]        if len(available_features) < len(features):        missing = set(features) - set(available_features)        print(f\"Warning: Missing features: {missing}\")        df_work = df[available_features + [target]].copy()        # Handle missing values    for col in available_features:        if df_work[col].dtype == \"object\":            mode_val = df_work[col].mode()[0] if len(df_work[col].mode()) > 0 else \"Unknown\"            df_work[col] = df_work[col].fillna(mode_val)        else:            df_work[col] = df_work[col].fillna(df_work[col].median())        # Encode categorical features    encoders = {}    for col in available_features:        if df_work[col].dtype == \"object\":            le = LabelEncoder()            df_work[col] = le.fit_transform(df_work[col].astype(str))            encoders[col] = le        # Prepare features and target    X = df_work[available_features]    y = df_work[target]        # Train/Val/Test split: 70/15/15 (stratified)    X_temp, X_test, y_temp, y_test = train_test_split(        X, y, test_size=test_size, random_state=RANDOM_STATE, stratify=y    )        val_size_adjusted = val_size / (1 - test_size)    X_train, X_val, y_train, y_val = train_test_split(        X_temp, y_temp, test_size=val_size_adjusted,         random_state=RANDOM_STATE, stratify=y_temp    )        # Scale features    scaler = StandardScaler()    X_train_scaled = scaler.fit_transform(X_train)    X_val_scaled = scaler.transform(X_val)    X_test_scaled = scaler.transform(X_test)        # Apply SMOTE to training data    smote = SMOTE(random_state=RANDOM_STATE)    X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)        print(f\"  Train: {X_train.shape[0]} → {X_train_smote.shape[0]} (after SMOTE)\")    print(f\"  Val:   {X_val.shape[0]}\")    print(f\"  Test:  {X_test.shape[0]}\")        return X_train_smote, X_val_scaled, X_test_scaled, y_train_smote, y_val, y_test, encoders, scalerprint(\"✓ Data preparation function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5L_L80pk8yl"
      },
      "source": [
        "## Section 8: Evaluation Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3Nvd68vk8yl"
      },
      "outputs": [],
      "source": [
        "def calculate_ks_statistic(y_true, y_pred_proba):\n",
        "    \"\"\"Calculate Kolmogorov-Smirnov statistic\"\"\"\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
        "    ks_statistic = max(tpr - fpr)\n",
        "    return ks_statistic\n",
        "\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, model_name):\n",
        "    \"\"\"\n",
        "    Comprehensive model evaluation\n",
        "\n",
        "    Returns dict with all 6 metrics\n",
        "    \"\"\"\n",
        "    # Predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Calculate all metrics\n",
        "    metrics = {\n",
        "        'Model': model_name,\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
        "        'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
        "        'F1-Score': f1_score(y_test, y_pred, zero_division=0),\n",
        "        'ROC-AUC': roc_auc_score(y_test, y_pred_proba),\n",
        "        'KS Statistic': calculate_ks_statistic(y_test, y_pred_proba)\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "print(\"✓ Evaluation functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ9Wxvlnk8yl"
      },
      "source": [
        "## Section 9: V1 Model Training and EvaluationTraining 5 models with 12 traditional features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AycZg5PLk8yl"
      },
      "outputs": [],
      "source": [
        "# Prepare V1 dataprint(\"Preparing V1 dataset...\")X_train_v1, X_val_v1, X_test_v1, y_train_v1, y_val_v1, y_test_v1, encoders_v1, scaler_v1 = prepare_data(    df, V1_FEATURES, TARGET)# Store all resultsall_results = []# Model configurations (using simpler hyperparameters for faster training)v1_models = {    'Logistic Regression V1': LogisticRegression(        random_state=RANDOM_STATE, max_iter=1000, C=0.1    ),    'Random Forest V1': RandomForestClassifier(        n_estimators=100, max_depth=10, random_state=RANDOM_STATE, n_jobs=-1    ),    'XGBoost V1': XGBClassifier(        n_estimators=100, max_depth=6, learning_rate=0.1,        random_state=RANDOM_STATE, eval_metric='logloss', use_label_encoder=False    ),    'LightGBM V1': LGBMClassifier(        n_estimators=100, max_depth=6, learning_rate=0.1,        random_state=RANDOM_STATE, verbose=-1    ),    'CatBoost V1': CatBoostClassifier(        iterations=100, depth=6, learning_rate=0.1,        random_state=RANDOM_STATE, verbose=False    )}print(\"\\n\" + \"=\"*80)print(\"TRAINING AND EVALUATING V1 MODELS\")print(\"=\"*80)for model_name, model in v1_models.items():    print(f\"\\nTraining {model_name}...\")    model.fit(X_train_v1, y_train_v1)        # Evaluate    metrics = evaluate_model(model, X_test_v1, y_test_v1, model_name)    all_results.append(metrics)        print(f\"  ROC-AUC: {metrics['ROC-AUC']:.4f} | KS: {metrics['KS Statistic']:.4f} | F1: {metrics['F1-Score']:.4f}\")print(\"\\n✓ V1 models training complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVHvHiPPk8ym"
      },
      "source": [
        "## Section 10: V2 Model Training and EvaluationTraining 15 models across 3 feature sets (A, B, C)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5D8bVV8kk8ym"
      },
      "outputs": [],
      "source": [
        "# Feature sets dictionaryfeature_sets = {    'A': FEATURES_A,    'B': FEATURES_B,    'C': FEATURES_C}print(\"\\n\" + \"=\"*80)print(\"TRAINING AND EVALUATING V2 MODELS\")print(\"=\"*80)# Train models for each feature setfor set_name, features in feature_sets.items():    print(f\"\\n{'='*80}\")    print(f\"FEATURE SET {set_name} ({len(features)} features)\")    print(f\"{'='*80}\")        # Prepare data for this feature set    print(f\"\\nPreparing Feature Set {set_name} dataset...\")    X_train, X_val, X_test, y_train, y_val, y_test, encoders, scaler = prepare_data(        df, features, TARGET    )        # Define models    v2_models = {        f'Logistic Regression V2 Feature Set {set_name}': LogisticRegression(            random_state=RANDOM_STATE, max_iter=1000, C=0.1        ),        f'Random Forest V2 Feature Set {set_name}': RandomForestClassifier(            n_estimators=100, max_depth=10, random_state=RANDOM_STATE, n_jobs=-1        ),        f'XGBoost V2 Feature Set {set_name}': XGBClassifier(            n_estimators=100, max_depth=6, learning_rate=0.1,            random_state=RANDOM_STATE, eval_metric='logloss', use_label_encoder=False        ),        f'LightGBM V2 Feature Set {set_name}': LGBMClassifier(            n_estimators=100, max_depth=6, learning_rate=0.1,            random_state=RANDOM_STATE, verbose=-1        ),        f'CatBoost V2 Feature Set {set_name}': CatBoostClassifier(            iterations=100, depth=6, learning_rate=0.1,            random_state=RANDOM_STATE, verbose=False        )    }        # Train and evaluate each model    for model_name, model in v2_models.items():        print(f\"\\nTraining {model_name}...\")        model.fit(X_train, y_train)                # Evaluate        metrics = evaluate_model(model, X_test, y_test, model_name)        all_results.append(metrics)                print(f\"  ROC-AUC: {metrics['ROC-AUC']:.4f} | KS: {metrics['KS Statistic']:.4f} | F1: {metrics['F1-Score']:.4f}\")print(\"\\n✓ V2 models training complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EJHklwFk8ym"
      },
      "source": [
        "## Section 11: Results Compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHboU70Vk8ym"
      },
      "outputs": [],
      "source": [
        "# Create comprehensive results DataFrameresults_df = pd.DataFrame(all_results)results_df = results_df.round(4)# Sort by ROC-AUC descendingresults_df = results_df.sort_values('ROC-AUC', ascending=False).reset_index(drop=True)# Display resultsprint(\"\\n\" + \"=\"*100)print(\"COMPREHENSIVE MODEL EVALUATION RESULTS\")print(\"=\"*100)print(results_df.to_string(index=False))print(\"=\"*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHKLP7SQk8yn"
      },
      "source": [
        "## Section 12: Visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1pnez7kk8yn"
      },
      "source": [
        "### A. ROC-AUC Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zgrCchHk8yn"
      },
      "outputs": [],
      "source": [
        "# ROC-AUC Comparison Bar Chartplt.figure(figsize=(14, 10))colors = ['steelblue' if 'V1' in model else 'coral' for model in results_df['Model']]plt.barh(results_df['Model'], results_df['ROC-AUC'], color=colors)plt.axvline(x=0.60, color='red', linestyle='--', linewidth=2, label='Baseline (0.60)')plt.axvline(x=0.68, color='green', linestyle='--', linewidth=2, label='Target (0.68)')plt.xlabel('ROC-AUC Score', fontsize=12)plt.ylabel('Model', fontsize=12)plt.title('Model Comparison: ROC-AUC Performance', fontsize=14, fontweight='bold')plt.legend(fontsize=10)plt.xlim(0.5, max(results_df['ROC-AUC']) + 0.05)plt.grid(axis='x', alpha=0.3)plt.tight_layout()plt.savefig('../models/roc_auc_comparison.png', dpi=300, bbox_inches='tight')plt.show()print(\"✓ ROC-AUC comparison chart saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuuo41Ckk8yn"
      },
      "source": [
        "### B. KS Statistic Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mw_jf5Hrk8yn"
      },
      "outputs": [],
      "source": [
        "# KS Statistic Comparison Bar Chartplt.figure(figsize=(14, 10))colors = ['steelblue' if 'V1' in model else 'coral' for model in results_df['Model']]plt.barh(results_df['Model'], results_df['KS Statistic'], color=colors)plt.axvline(x=0.21, color='red', linestyle='--', linewidth=2, label='Baseline (0.21)')plt.axvline(x=0.28, color='green', linestyle='--', linewidth=2, label='Target (0.28)')plt.xlabel('KS Statistic', fontsize=12)plt.ylabel('Model', fontsize=12)plt.title('Model Comparison: Kolmogorov-Smirnov Statistic', fontsize=14, fontweight='bold')plt.legend(fontsize=10)plt.xlim(0.15, max(results_df['KS Statistic']) + 0.05)plt.grid(axis='x', alpha=0.3)plt.tight_layout()plt.savefig('../models/ks_statistic_comparison.png', dpi=300, bbox_inches='tight')plt.show()print(\"✓ KS Statistic comparison chart saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByEFhOHek8yn"
      },
      "source": [
        "### C. Performance Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlzZ1qjFk8yo"
      },
      "outputs": [],
      "source": [
        "# Performance Heatmap showing all metrics for all modelsplt.figure(figsize=(12, 14))metrics_for_heatmap = results_df.set_index('Model')[['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC', 'KS Statistic']]sns.heatmap(metrics_for_heatmap, annot=True, fmt='.4f', cmap='RdYlGn',             center=0.65, linewidths=0.5, cbar_kws={'label': 'Score'})plt.title('Model Performance Heatmap - All Metrics', fontsize=14, fontweight='bold')plt.xlabel('Metrics', fontsize=12)plt.ylabel('Model', fontsize=12)plt.tight_layout()plt.savefig('../models/performance_heatmap.png', dpi=300, bbox_inches='tight')plt.show()print(\"✓ Performance heatmap saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVQGs432k8yo"
      },
      "source": [
        "### D. Multi-Metric Radar Chart (Top 5 Models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eA9I_hIMk8yo"
      },
      "outputs": [],
      "source": [
        "# Radar chart for top 5 modelstop_5 = results_df.head(5)categories = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC', 'KS Statistic']N = len(categories)# Create angles for each metricangles = [n / float(N) * 2 * pi for n in range(N)]angles += angles[:1]  # Complete the circle# Create plotfig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))# Plot each modelcolors_radar = plt.cm.Set3(np.linspace(0, 1, 5))for idx, (_, row) in enumerate(top_5.iterrows()):    values = [row['Accuracy'], row['Precision'], row['Recall'],               row['F1-Score'], row['ROC-AUC'], row['KS Statistic']]    values += values[:1]  # Complete the circle        ax.plot(angles, values, 'o-', linewidth=2, label=row['Model'], color=colors_radar[idx])    ax.fill(angles, values, alpha=0.15, color=colors_radar[idx])# Customize plotax.set_xticks(angles[:-1])ax.set_xticklabels(categories, size=10)ax.set_ylim(0, 1)ax.set_yticks([0.2, 0.4, 0.6, 0.8])ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8'], size=8)ax.grid(True, linestyle='--', alpha=0.7)ax.set_title('Top 5 Models: Multi-Metric Comparison', size=14, fontweight='bold', pad=20)plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=9)plt.tight_layout()plt.savefig('../models/top5_radar_chart.png', dpi=300, bbox_inches='tight')plt.show()print(\"✓ Radar chart saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h5K0NbNk8yo"
      },
      "source": [
        "### E. Confusion Matrix (Best Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ddr2AxNSk8yo"
      },
      "outputs": [],
      "source": [
        "# Get the best model name and retrain to get confusion matrixbest_model_name = results_df.iloc[0]['Model']print(f\"\\nGenerating confusion matrix for: {best_model_name}\")# Determine which dataset to use based on model nameif 'V1' in best_model_name and 'V2' not in best_model_name:    X_test_best = X_test_v1    y_test_best = y_test_v1    X_train_best = X_train_v1    y_train_best = y_train_v1elif 'Feature Set A' in best_model_name:    X_train_best, _, X_test_best, y_train_best, _, y_test_best, _, _ = prepare_data(df, FEATURES_A, TARGET)elif 'Feature Set B' in best_model_name:    X_train_best, _, X_test_best, y_train_best, _, y_test_best, _, _ = prepare_data(df, FEATURES_B, TARGET)else:  # Feature Set C    X_train_best, _, X_test_best, y_train_best, _, y_test_best, _, _ = prepare_data(df, FEATURES_C, TARGET)# Retrain the best modelif 'Logistic Regression' in best_model_name:    best_model = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000, C=0.1)elif 'Random Forest' in best_model_name:    best_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=RANDOM_STATE, n_jobs=-1)elif 'XGBoost' in best_model_name:    best_model = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1,                               random_state=RANDOM_STATE, eval_metric='logloss', use_label_encoder=False)elif 'LightGBM' in best_model_name:    best_model = LGBMClassifier(n_estimators=100, max_depth=6, learning_rate=0.1,                                random_state=RANDOM_STATE, verbose=-1)else:  # CatBoost    best_model = CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1,                                    random_state=RANDOM_STATE, verbose=False)best_model.fit(X_train_best, y_train_best)y_pred_best = best_model.predict(X_test_best)# Generate confusion matrixcm = confusion_matrix(y_test_best, y_pred_best)disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Paid', 'Defaulted'])fig, ax = plt.subplots(figsize=(8, 6))disp.plot(ax=ax, cmap='Blues', values_format='d')plt.title(f'Confusion Matrix: {best_model_name}', fontsize=14, fontweight='bold')plt.tight_layout()plt.savefig('../models/best_model_confusion_matrix.png', dpi=300, bbox_inches='tight')plt.show()print(\"✓ Confusion matrix saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0fyU_wBk8yo"
      },
      "source": [
        "## Section 13: Summary Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZClT6pSTk8yo"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY STATISTICS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Best performing model\n",
        "best_model = results_df.iloc[0]\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"BEST MODEL\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"Model: {best_model['Model']}\")\n",
        "print(f\"  Accuracy:      {best_model['Accuracy']:.4f}\")\n",
        "print(f\"  Precision:     {best_model['Precision']:.4f}\")\n",
        "print(f\"  Recall:        {best_model['Recall']:.4f}\")\n",
        "print(f\"  F1-Score:      {best_model['F1-Score']:.4f}\")\n",
        "print(f\"  ROC-AUC:       {best_model['ROC-AUC']:.4f}\")\n",
        "print(f\"  KS Statistic:  {best_model['KS Statistic']:.4f}\")\n",
        "\n",
        "# V1 vs V2 comparison\n",
        "v1_results = results_df[results_df['Model'].str.contains('V1') & ~results_df['Model'].str.contains('V2')]\n",
        "v2_results = results_df[results_df['Model'].str.contains('V2')]\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"V1 vs V2 COMPARISON\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"\\nV1 Models (n={len(v1_results)}):\")\n",
        "print(f\"  Average ROC-AUC:      {v1_results['ROC-AUC'].mean():.4f}\")\n",
        "print(f\"  Average KS Statistic: {v1_results['KS Statistic'].mean():.4f}\")\n",
        "print(f\"  Average F1-Score:     {v1_results['F1-Score'].mean():.4f}\")\n",
        "\n",
        "print(f\"\\nV2 Models (n={len(v2_results)}):\")\n",
        "print(f\"  Average ROC-AUC:      {v2_results['ROC-AUC'].mean():.4f}\")\n",
        "print(f\"  Average KS Statistic: {v2_results['KS Statistic'].mean():.4f}\")\n",
        "print(f\"  Average F1-Score:     {v2_results['F1-Score'].mean():.4f}\")\n",
        "\n",
        "if len(v1_results) > 0 and len(v2_results) > 0:\n",
        "    roc_improvement = ((v2_results['ROC-AUC'].mean() - v1_results['ROC-AUC'].mean()) / v1_results['ROC-AUC'].mean() * 100)\n",
        "    ks_improvement = ((v2_results['KS Statistic'].mean() - v1_results['KS Statistic'].mean()) / v1_results['KS Statistic'].mean() * 100)\n",
        "\n",
        "    print(f\"\\nImprovement:\")\n",
        "    print(f\"  ROC-AUC:      {roc_improvement:+.2f}%\")\n",
        "    print(f\"  KS Statistic: {ks_improvement:+.2f}%\")\n",
        "\n",
        "# Feature set comparison (V2 only)\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"FEATURE SET COMPARISON (V2 MODELS)\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "for feature_set in ['A', 'B', 'C']:\n",
        "    fs_results = v2_results[v2_results['Model'].str.contains(f'Feature Set {feature_set}')]\n",
        "    if len(fs_results) > 0:\n",
        "        print(f\"\\nFeature Set {feature_set} (n={len(fs_results)}):\")\n",
        "        print(f\"  Average ROC-AUC:      {fs_results['ROC-AUC'].mean():.4f}\")\n",
        "        print(f\"  Average KS Statistic: {fs_results['KS Statistic'].mean():.4f}\")\n",
        "        print(f\"  Average F1-Score:     {fs_results['F1-Score'].mean():.4f}\")\n",
        "        print(f\"  Best Model: {fs_results.iloc[0]['Model']}\")\n",
        "        print(f\"    ROC-AUC: {fs_results.iloc[0]['ROC-AUC']:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcHpMxk3k8yp"
      },
      "source": [
        "## Section 14: Export Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ez5EF9x3k8yp"
      },
      "outputs": [],
      "source": [
        "# Save results to CSVcsv_path = '../models/model_evaluation_results.csv'results_df.to_csv(csv_path, index=False)print(f\"\\n✓ Results saved to: {csv_path}\")# Create markdown reportmd_path = '../models/MODEL_EVALUATION_REPORT.md'with open(md_path, 'w') as f:    f.write(\"# Model Evaluation Report\\n\\n\")    f.write(\"## Executive Summary\\n\\n\")    f.write(f\"Evaluated **{len(results_df)}** models across V1 and V2 architectures.\\n\\n\")        f.write(\"## Best Model\\n\\n\")    f.write(f\"**{best_model['Model']}**\\n\\n\")    f.write(f\"- Accuracy: {best_model['Accuracy']:.4f}\\n\")    f.write(f\"- Precision: {best_model['Precision']:.4f}\\n\")    f.write(f\"- Recall: {best_model['Recall']:.4f}\\n\")    f.write(f\"- F1-Score: {best_model['F1-Score']:.4f}\\n\")    f.write(f\"- ROC-AUC: {best_model['ROC-AUC']:.4f}\\n\")    f.write(f\"- KS Statistic: {best_model['KS Statistic']:.4f}\\n\\n\")        f.write(\"## Complete Results\\n\\n\")    f.write(results_df.to_markdown(index=False))    f.write(\"\\n\\n\")        f.write(\"## V1 vs V2 Comparison\\n\\n\")    f.write(f\"| Model Version | Avg ROC-AUC | Avg KS Stat | Avg F1-Score |\\n\")    f.write(f\"|---------------|-------------|-------------|--------------|\\n\")    f.write(f\"| V1 Models     | {v1_results['ROC-AUC'].mean():.4f}      | {v1_results['KS Statistic'].mean():.4f}      | {v1_results['F1-Score'].mean():.4f}       |\\n\")    f.write(f\"| V2 Models     | {v2_results['ROC-AUC'].mean():.4f}      | {v2_results['KS Statistic'].mean():.4f}      | {v2_results['F1-Score'].mean():.4f}       |\\n\")        if len(v1_results) > 0 and len(v2_results) > 0:        roc_improvement = ((v2_results['ROC-AUC'].mean() - v1_results['ROC-AUC'].mean()) / v1_results['ROC-AUC'].mean() * 100)        f.write(f\"\\n**Improvement: {roc_improvement:+.2f}% in ROC-AUC**\\n\")        f.write(\"\\n## Feature Set Performance (V2)\\n\\n\")    for feature_set in ['A', 'B', 'C']:        fs_results = v2_results[v2_results['Model'].str.contains(f'Feature Set {feature_set}')]        if len(fs_results) > 0:            f.write(f\"\\n### Feature Set {feature_set}\\n\")            f.write(f\"- Average ROC-AUC: {fs_results['ROC-AUC'].mean():.4f}\\n\")            f.write(f\"- Average KS Statistic: {fs_results['KS Statistic'].mean():.4f}\\n\")            f.write(f\"- Best Model: {fs_results.iloc[0]['Model']} (ROC-AUC: {fs_results.iloc[0]['ROC-AUC']:.4f})\\n\")print(f\"✓ Markdown report saved to: {md_path}\")print(\"\\n\" + \"=\"*80)print(\"MODEL EVALUATION COMPLETE\")print(\"=\"*80)print(f\"\\nDeliverables:\")print(f\"  1. CSV Results:       {csv_path}\")print(f\"  2. Markdown Report:   {md_path}\")print(f\"  3. ROC-AUC Chart:     ../models/roc_auc_comparison.png\")print(f\"  4. KS Stat Chart:     ../models/ks_statistic_comparison.png\")print(f\"  5. Heatmap:           ../models/performance_heatmap.png\")print(f\"  6. Radar Chart:       ../models/top5_radar_chart.png\")print(f\"  7. Confusion Matrix:  ../models/best_model_confusion_matrix.png\")print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gains Table Summary"
      ],
      "metadata": {
        "id": "t_jp2uhjlIQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# COMPLETE SETUP - RUN THIS FIRST\n",
        "# ============================================\n",
        "\n",
        "# 1. Install libraries\n",
        "print(\"Installing libraries...\")\n",
        "!pip install xgboost lightgbm catboost imbalanced-learn shap tabulate -q\n",
        "print(\"✓ Libraries installed\\n\")\n",
        "\n",
        "# 2. Import everything\n",
        "print(\"Importing libraries...\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn. ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, roc_curve, confusion_matrix\n",
        ")\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "RANDOM_STATE = 42\n",
        "TARGET = 'Defaulted'\n",
        "\n",
        "print(\"✓ Libraries imported\\n\")\n",
        "\n",
        "# 3. Upload your data file\n",
        "print(\"Please upload your CSV file...\")\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the filename\n",
        "filename = list(uploaded.keys())[0]\n",
        "print(f\"\\n✓ File uploaded: {filename}\\n\")\n",
        "\n",
        "# 4. Load the data\n",
        "df = pd.read_csv(filename, encoding='latin-1')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DATA LOADED SUCCESSFULLY!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Total rows (customers):    {len(df)}\")\n",
        "print(f\"Total columns (features):  {len(df.columns)}\")\n",
        "print(f\"\\nTarget variable:  {TARGET}\")\n",
        "if TARGET in df.columns:\n",
        "    print(f\"  Good (0): {(df[TARGET] == 0).sum()}\")\n",
        "    print(f\"  Bad (1):  {(df[TARGET] == 1).sum()}\")\n",
        "    print(f\"  Default rate: {df[TARGET].mean() * 100:.2f}%\")\n",
        "else:\n",
        "    print(f\"  ⚠ Warning: '{TARGET}' column not found!\")\n",
        "    print(f\"  Available columns:  {df.columns.tolist()[: 10]}...\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "CvdEbGv6mWTI",
        "outputId": "ea011cc9-8146-4ba3-aee0-838c8968ca63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing libraries...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✓ Libraries installed\n",
            "\n",
            "Importing libraries...\n",
            "✓ Libraries imported\n",
            "\n",
            "Please upload your CSV file...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-128ac873-32c3-4bde-b97e-921c077b79c1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-128ac873-32c3-4bde-b97e-921c077b79c1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Github Original Data.csv to Github Original Data.csv\n",
            "\n",
            "✓ File uploaded: Github Original Data.csv\n",
            "\n",
            "================================================================================\n",
            "DATA LOADED SUCCESSFULLY!\n",
            "================================================================================\n",
            "Total rows (customers):    559\n",
            "Total columns (features):  101\n",
            "\n",
            "Target variable:  Defaulted\n",
            "  Good (0): 343\n",
            "  Bad (1):  216\n",
            "  Default rate: 38.64%\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# GENERATE COMPOSITE SCORES FOR ALL 559 CUSTOMERS\n",
        "# ============================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"Generating composite scores for all 559 customers...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Step 1: Define composite score functions\n",
        "def calculate_financial_resilience(row):\n",
        "    \"\"\"\n",
        "    Financial Resilience Score (0-100)\n",
        "    Weights: Extra Income (35%), Expense Ratio (30%), Income Diversity (20%), Savings (15%)\n",
        "    \"\"\"\n",
        "    score = 0\n",
        "\n",
        "    # Extra Income Level (35% weight)\n",
        "    extra_income = str(row. get('Extra_Income_Brackets', '')).lower()\n",
        "    if 'moderate' in extra_income or 'high' in extra_income:\n",
        "        score += 35 * 1.0\n",
        "    elif 'low' in extra_income and 'no' not in extra_income:\n",
        "        score += 35 * 0.3\n",
        "    else:\n",
        "        score += 35 * 0.6\n",
        "\n",
        "    # Expense-to-Income Ratio (30% weight)\n",
        "    expense_ratio = str(row.get('Expense_Ratio', '')).lower()\n",
        "    if '1/3' in expense_ratio:\n",
        "        score += 30 * 1.0\n",
        "    elif 'half' in expense_ratio:\n",
        "        score += 30 * 0.7\n",
        "    elif '2/3' in expense_ratio and 'more' not in expense_ratio:\n",
        "        score += 30 * 0.4\n",
        "    else:\n",
        "        score += 30 * 0.5\n",
        "\n",
        "    # Income Diversity (20% weight)\n",
        "    income_div = str(row.get('Income_Diversity', '')).lower()\n",
        "    if 'full' in income_div:\n",
        "        score += 20 * 1.0\n",
        "    elif 'regular' in income_div:\n",
        "        score += 20 * 0.7\n",
        "    elif 'extra' in income_div:\n",
        "        score += 20 * 0.5\n",
        "    else:\n",
        "        score += 20 * 0.6\n",
        "\n",
        "    # Savings Level (15% weight)\n",
        "    savings = str(row.get('Savings_Category', '')).lower()\n",
        "    if 'high' in savings:\n",
        "        score += 15 * 1.0\n",
        "    elif 'low' in savings and 'no' not in savings:\n",
        "        score += 15 * 0.8\n",
        "    else:\n",
        "        score += 15 * 0.6\n",
        "\n",
        "    return score\n",
        "\n",
        "def calculate_business_quality(row):\n",
        "    \"\"\"\n",
        "    Business Quality Score (0-100)\n",
        "    Weights: Rent (45%), Utility (30%), Business Affordability (25%)\n",
        "    \"\"\"\n",
        "    score = 0\n",
        "\n",
        "    # Rent Payment Level (45% weight)\n",
        "    rent = str(row.get('Rent_Category', '')).lower()\n",
        "    if 'high' in rent:\n",
        "        score += 45 * 1.0\n",
        "    elif 'low' in rent and 'no' not in rent:\n",
        "        score += 45 * 0.5\n",
        "    else:\n",
        "        score += 45 * 0.6\n",
        "\n",
        "    # Utility Expenses (30% weight)\n",
        "    utility = str(row.get('Utility_Category', '')).lower()\n",
        "    if 'high' in utility:\n",
        "        score += 30 * 1.0\n",
        "    elif 'low' in utility and 'no' not in utility:\n",
        "        score += 30 * 0.5\n",
        "    else:\n",
        "        score += 30 * 0.7\n",
        "\n",
        "    # Business Affordability (25% weight)\n",
        "    afford = str(row.get('Affordability_Business', '')).lower()\n",
        "    if 'profitable' in afford:\n",
        "        score += 25 * 1.0\n",
        "    else:\n",
        "        score += 25 * 0.5\n",
        "\n",
        "    return score\n",
        "\n",
        "def calculate_stability(row):\n",
        "    \"\"\"\n",
        "    Stability Score (0-100)\n",
        "    Weights: School Fees (40%), Regular Income (30%), Income Streams (30%)\n",
        "    \"\"\"\n",
        "    score = 0\n",
        "\n",
        "    # School Fees Commitment (40% weight)\n",
        "    school = str(row.get('SchoolFees_Category', '')).lower()\n",
        "    if 'high' in school:\n",
        "        score += 40 * 1.0\n",
        "    elif 'low' in school and 'no' not in school:\n",
        "        score += 40 * 0.5\n",
        "    else:\n",
        "        score += 40 * 0.9\n",
        "\n",
        "    # Regular Income Presence (30% weight)\n",
        "    regular = str(row.get('Regular_Income_Brackets', '')).lower()\n",
        "    if 'moderate' in regular or 'high' in regular:\n",
        "        score += 30 * 1.0\n",
        "    elif 'low' in regular and 'no' not in regular:\n",
        "        score += 30 * 1.1\n",
        "    else:\n",
        "        score += 30 * 0.85\n",
        "\n",
        "    # Multiple Income Streams (30% weight)\n",
        "    income_div = str(row.get('Income_Diversity', '')).lower()\n",
        "    if 'full' in income_div:\n",
        "        score += 30 * 1.0\n",
        "    elif 'regular' in income_div:\n",
        "        score += 30 * 0.8\n",
        "    elif 'extra' in income_div:\n",
        "        score += 30 * 0.6\n",
        "    else:\n",
        "        score += 30 * 0.7\n",
        "\n",
        "    return min(score, 100)\n",
        "\n",
        "def calculate_expense_management(row):\n",
        "    \"\"\"\n",
        "    Expense Management Score (0-100)\n",
        "    Weights: Expense Ratio (50%), Affordability HH (35%), Utility (15%)\n",
        "    \"\"\"\n",
        "    score = 0\n",
        "\n",
        "    # Expense Relative to Income (50% weight)\n",
        "    expense_ratio = str(row.get('Expense_Ratio', '')).lower()\n",
        "    if '1/3' in expense_ratio:\n",
        "        score += 50 * 1.0\n",
        "    elif 'half' in expense_ratio:\n",
        "        score += 50 * 0.7\n",
        "    elif '2/3' in expense_ratio and 'more' not in expense_ratio:\n",
        "        score += 50 * 0.4\n",
        "    else:\n",
        "        score += 50 * 0.5\n",
        "\n",
        "    # Affordability HH (35% weight)\n",
        "    afford = str(row.get('Affordability_HH', '')).lower()\n",
        "    if 'profitable' in afford:\n",
        "        score += 35 * 1.0\n",
        "    else:\n",
        "        score += 35 * 0.5\n",
        "\n",
        "    # Utility Expenses (15% weight)\n",
        "    utility = str(row.get('Utility_Category', '')).lower()\n",
        "    if 'high' in utility:\n",
        "        score += 15 * 1.0\n",
        "    elif 'low' in utility and 'no' not in utility:\n",
        "        score += 15 * 0.5\n",
        "    else:\n",
        "        score += 15 * 0.7\n",
        "\n",
        "    return score\n",
        "\n",
        "print(\"✓ Composite score functions defined\")\n",
        "\n",
        "# Step 2: Prepare intermediate features\n",
        "print(\"\\nPreparing intermediate features...\")\n",
        "\n",
        "# Affordability Business\n",
        "if \"Affordability\" in df.columns:\n",
        "    df[\"Affordability_Business\"] = df[\"Affordability\"].fillna(\"Unknown\")\n",
        "else:\n",
        "    df[\"Affordability_Business\"] = \"Unknown\"\n",
        "\n",
        "# Affordability HH (Household)\n",
        "if \"Affordability (HH)\" in df.columns:\n",
        "    df[\"Affordability_HH\"] = df[\"Affordability (HH)\"].fillna(\"Unknown\")\n",
        "else:\n",
        "    df[\"Affordability_HH\"] = df. get(\"Affordability_Business\", \"Unknown\")\n",
        "\n",
        "# Extra Income Brackets\n",
        "if \"Extra Income Brackets\" in df.columns:\n",
        "    df[\"Extra_Income_Brackets\"] = df[\"Extra Income Brackets\"].fillna(\"No Extra Income\")\n",
        "else:\n",
        "    extra_income = pd.to_numeric(df. get(\"Extra Income\", 0), errors=\"coerce\").fillna(0)\n",
        "    df[\"Extra_Income_Brackets\"] = np.where(\n",
        "        extra_income == 0, \"No Extra Income\",\n",
        "        np.where(extra_income < 5000, \"Low Extra Income\",\n",
        "        np.where(extra_income < 10000, \"Moderate Extra Income\", \"High Extra Income\"))\n",
        "    )\n",
        "\n",
        "# Expense Ratio\n",
        "if \"Expense Relative to Income\" in df.columns:\n",
        "    df[\"Expense_Ratio\"] = df[\"Expense Relative to Income\"].fillna(\"Unknown\")\n",
        "else:\n",
        "    df[\"Expense_Ratio\"] = \"Unknown\"\n",
        "\n",
        "# Income Diversity\n",
        "if \"Logic on Income\" in df.columns:\n",
        "    df[\"Income_Diversity\"] = df[\"Logic on Income\"].fillna(\"Unknown\")\n",
        "else:\n",
        "    df[\"Income_Diversity\"] = \"Unknown\"\n",
        "\n",
        "# Savings Category\n",
        "if \"Savings\" in df.columns:\n",
        "    df[\"Savings_Category\"] = df[\"Savings\"]. fillna(\"No Savings\")\n",
        "else:\n",
        "    df[\"Savings_Category\"] = \"No Savings\"\n",
        "\n",
        "# Rent Category\n",
        "if \"Categorize Rent Payment\" in df.columns:\n",
        "    df[\"Rent_Category\"] = df[\"Categorize Rent Payment\"].fillna(\"No Rent\")\n",
        "else:\n",
        "    df[\"Rent_Category\"] = \"No Rent\"\n",
        "\n",
        "# Utility Category\n",
        "if \"Categorizing Utility Expenses\" in df. columns:\n",
        "    df[\"Utility_Category\"] = df[\"Categorizing Utility Expenses\"].fillna(\"None\")\n",
        "else:\n",
        "    df[\"Utility_Category\"] = \"None\"\n",
        "\n",
        "# School Fees Category\n",
        "if \"School Fees Categorical\" in df.columns:\n",
        "    df[\"SchoolFees_Category\"] = df[\"School Fees Categorical\"].fillna(\"None\")\n",
        "else:\n",
        "    df[\"SchoolFees_Category\"] = \"None\"\n",
        "\n",
        "# Regular Income Brackets\n",
        "if \"Regular Income\" in df.columns:\n",
        "    regular_income = pd.to_numeric(df[\"Regular Income\"], errors=\"coerce\").fillna(0)\n",
        "    df[\"Regular_Income_Brackets\"] = np.where(\n",
        "        regular_income == 0, \"No Regular Income\",\n",
        "        np.where(regular_income < 10000, \"Low Regular Income\",\n",
        "        np.where(regular_income < 20000, \"Moderate Regular Income\", \"High Regular Income\"))\n",
        "    )\n",
        "else:\n",
        "    df[\"Regular_Income_Brackets\"] = \"Unknown\"\n",
        "\n",
        "print(\"✓ Intermediate features prepared\")\n",
        "\n",
        "# Step 3: Generate the 4 composite scores\n",
        "print(\"\\nGenerating composite scores...\")\n",
        "\n",
        "df[\"Financial_Resilience_Score\"] = df.apply(calculate_financial_resilience, axis=1)\n",
        "df[\"Business_Quality_Score\"] = df.apply(calculate_business_quality, axis=1)\n",
        "df[\"Stability_Score\"] = df.apply(calculate_stability, axis=1)\n",
        "df[\"Expense_Management_Score\"] = df.apply(calculate_expense_management, axis=1)\n",
        "\n",
        "print(\"✓ Composite scores generated!\")\n",
        "\n",
        "# Step 4: Display summary\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPOSITE SCORES SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "composite_cols = [\"Financial_Resilience_Score\", \"Business_Quality_Score\",\n",
        "                  \"Stability_Score\", \"Expense_Management_Score\"]\n",
        "\n",
        "for col in composite_cols:\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(f\"  Mean:  {df[col].mean():.2f}\")\n",
        "    print(f\"  Std:   {df[col].std():.2f}\")\n",
        "    print(f\"  Min:   {df[col]. min():.2f}\")\n",
        "    print(f\"  Max:   {df[col].max():.2f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"✓ ALL COMPOSITE SCORES READY!\")\n",
        "print(\"  You can now create the scorecard\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "SEpBHmrxodPg",
        "outputId": "42d74e31-ed12-4b1a-ff21-f84a6f4eca46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating composite scores for all 559 customers...\n",
            "================================================================================\n",
            "✓ Composite score functions defined\n",
            "\n",
            "Preparing intermediate features...\n",
            "✓ Intermediate features prepared\n",
            "\n",
            "Generating composite scores...\n",
            "✓ Composite scores generated!\n",
            "\n",
            "================================================================================\n",
            "COMPOSITE SCORES SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Financial_Resilience_Score:\n",
            "  Mean:  61.25\n",
            "  Std:   12.03\n",
            "  Min:   41.50\n",
            "  Max:   94.00\n",
            "\n",
            "Business_Quality_Score:\n",
            "  Mean:  63.07\n",
            "  Std:   11.97\n",
            "  Min:   50.00\n",
            "  Max:   87.50\n",
            "\n",
            "Stability_Score:\n",
            "  Mean:  74.64\n",
            "  Std:   10.13\n",
            "  Min:   63.50\n",
            "  Max:   95.50\n",
            "\n",
            "Expense_Management_Score:\n",
            "  Mean:  67.45\n",
            "  Std:   15.27\n",
            "  Min:   45.00\n",
            "  Max:   100.00\n",
            "\n",
            "================================================================================\n",
            "✓ ALL COMPOSITE SCORES READY!\n",
            "  You can now create the scorecard\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CREATE COMPLETE SCORECARD FOR ALL 559 CUSTOMERS\n",
        "# ============================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "print(\"Creating customer scorecard for all 559 customers...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create necessary directories\n",
        "os.makedirs('models', exist_ok=True)\n",
        "print(\"✓ Directories created\")\n",
        "\n",
        "# Feature Sets\n",
        "FEATURES_A = [\n",
        "    'Financial_Resilience_Score',\n",
        "    'Business_Quality_Score',\n",
        "    'Stability_Score',\n",
        "    'Expense_Management_Score'\n",
        "]\n",
        "\n",
        "FEATURES_C = [\n",
        "    'Financial_Resilience_Score',\n",
        "    'Business_Quality_Score',\n",
        "    'Stability_Score',\n",
        "    'Expense_Management_Score',\n",
        "    'Age Group',\n",
        "    'Education',\n",
        "    'CRB Class',\n",
        "    'Living',\n",
        "    'Logic on Income',\n",
        "    'Marital status'\n",
        "]\n",
        "\n",
        "# Prepare data function\n",
        "def prepare_data(df, features, target, test_size=0.15, val_size=0.15):\n",
        "    \"\"\"Prepare data for training\"\"\"\n",
        "    available_features = [f for f in features if f in df.columns]\n",
        "\n",
        "    if len(available_features) < len(features):\n",
        "        missing = set(features) - set(available_features)\n",
        "        print(f\"   Warning: Missing features:  {missing}\")\n",
        "\n",
        "    df_work = df[available_features + [target]].copy()\n",
        "\n",
        "    # Handle missing values\n",
        "    for col in available_features:\n",
        "        if df_work[col].dtype == \"object\":\n",
        "            mode_val = df_work[col]. mode()[0] if len(df_work[col].mode()) > 0 else \"Unknown\"\n",
        "            df_work[col] = df_work[col]. fillna(mode_val)\n",
        "        else:\n",
        "            df_work[col] = df_work[col].fillna(df_work[col].median())\n",
        "\n",
        "    # Encode categorical features\n",
        "    encoders = {}\n",
        "    for col in available_features:\n",
        "        if df_work[col].dtype == \"object\":\n",
        "            le = LabelEncoder()\n",
        "            df_work[col] = le.fit_transform(df_work[col]. astype(str))\n",
        "            encoders[col] = le\n",
        "\n",
        "    X = df_work[available_features]\n",
        "    y = df_work[target]\n",
        "\n",
        "    # Train/Val/Test split\n",
        "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=RANDOM_STATE, stratify=y\n",
        "    )\n",
        "\n",
        "    val_size_adjusted = val_size / (1 - test_size)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_temp, y_temp, test_size=val_size_adjusted,\n",
        "        random_state=RANDOM_STATE, stratify=y_temp\n",
        "    )\n",
        "\n",
        "    # Scale\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_val_scaled = scaler.transform(X_val)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # SMOTE\n",
        "    smote = SMOTE(random_state=RANDOM_STATE)\n",
        "    X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "    return X_train_smote, X_val_scaled, X_test_scaled, y_train_smote, y_val, y_test, encoders, scaler\n",
        "\n",
        "# Step 1: Train XGBoost on Feature Set A\n",
        "print(\"\\n1. Training XGBoost V2 Feature Set A...\")\n",
        "X_train_a, X_val_a, X_test_a, y_train_a, y_val_a, y_test_a, encoders_a, scaler_a = prepare_data(\n",
        "    df, FEATURES_A, TARGET\n",
        ")\n",
        "\n",
        "xgb_a = XGBClassifier(\n",
        "    n_estimators=100, max_depth=6, learning_rate=0.1,\n",
        "    random_state=RANDOM_STATE, eval_metric='logloss', use_label_encoder=False\n",
        ")\n",
        "xgb_a.fit(X_train_a, y_train_a)\n",
        "print(\"   ✓ XGBoost trained\")\n",
        "\n",
        "# Step 2: Train LightGBM on Feature Set C\n",
        "print(\"\\n2. Training LightGBM V2 Feature Set C...\")\n",
        "X_train_c, X_val_c, X_test_c, y_train_c, y_val_c, y_test_c, encoders_c, scaler_c = prepare_data(\n",
        "    df, FEATURES_C, TARGET\n",
        ")\n",
        "\n",
        "lgbm_c = LGBMClassifier(\n",
        "    n_estimators=100, max_depth=6, learning_rate=0.1,\n",
        "    random_state=RANDOM_STATE, verbose=-1\n",
        ")\n",
        "lgbm_c.fit(X_train_c, y_train_c)\n",
        "print(\"   ✓ LightGBM trained\")\n",
        "\n",
        "# Step 3: Prepare ALL 559 customers for prediction\n",
        "print(f\"\\n3. Preparing all 559 customers for scoring...\")\n",
        "\n",
        "# For XGBoost (Feature Set A)\n",
        "df_for_xgb = df[FEATURES_A]. copy()\n",
        "for col in FEATURES_A:\n",
        "    if df_for_xgb[col].dtype == \"object\":\n",
        "        mode_val = df_for_xgb[col].mode()[0] if len(df_for_xgb[col].mode()) > 0 else \"Unknown\"\n",
        "        df_for_xgb[col] = df_for_xgb[col].fillna(mode_val)\n",
        "    else:\n",
        "        df_for_xgb[col] = df_for_xgb[col].fillna(df_for_xgb[col].median())\n",
        "\n",
        "for col in FEATURES_A:\n",
        "    if col in encoders_a:\n",
        "        df_for_xgb[col] = df_for_xgb[col].astype(str)\n",
        "        df_for_xgb[col] = df_for_xgb[col].apply(\n",
        "            lambda x: x if x in encoders_a[col].classes_ else encoders_a[col].classes_[0]\n",
        "        )\n",
        "        df_for_xgb[col] = encoders_a[col].transform(df_for_xgb[col])\n",
        "\n",
        "X_all_xgb = scaler_a.transform(df_for_xgb)\n",
        "\n",
        "# For LightGBM (Feature Set C)\n",
        "df_for_lgbm = df[FEATURES_C].copy()\n",
        "for col in FEATURES_C:\n",
        "    if df_for_lgbm[col].dtype == \"object\":\n",
        "        mode_val = df_for_lgbm[col]. mode()[0] if len(df_for_lgbm[col].mode()) > 0 else \"Unknown\"\n",
        "        df_for_lgbm[col] = df_for_lgbm[col].fillna(mode_val)\n",
        "    else:\n",
        "        df_for_lgbm[col] = df_for_lgbm[col].fillna(df_for_lgbm[col].median())\n",
        "\n",
        "for col in FEATURES_C:\n",
        "    if col in encoders_c:\n",
        "        df_for_lgbm[col] = df_for_lgbm[col].astype(str)\n",
        "        df_for_lgbm[col] = df_for_lgbm[col].apply(\n",
        "            lambda x: x if x in encoders_c[col].classes_ else encoders_c[col].classes_[0]\n",
        "        )\n",
        "        df_for_lgbm[col] = encoders_c[col].transform(df_for_lgbm[col])\n",
        "\n",
        "X_all_lgbm = scaler_c.transform(df_for_lgbm)\n",
        "\n",
        "print(\"   ✓ All customers prepared\")\n",
        "\n",
        "# Step 4: Generate predictions\n",
        "print(f\"\\n4. Generating predictions for all 559 customers...\")\n",
        "xgb_predictions = xgb_a.predict_proba(X_all_xgb)[:, 1] * 100\n",
        "lgbm_predictions = lgbm_c.predict_proba(X_all_lgbm)[:, 1] * 100\n",
        "print(\"   ✓ Predictions complete\")\n",
        "\n",
        "# Step 5: Create scorecard\n",
        "print(\"\\n5. Building scorecard table...\")\n",
        "\n",
        "scorecard = pd.DataFrame({\n",
        "    'ID': range(1, len(df) + 1),\n",
        "    'XGBoost V2 Feature Set A': xgb_predictions. round(2),\n",
        "    'LightGBM V2 Feature Set C': lgbm_predictions. round(2),\n",
        "    'Good or Bad?': df[TARGET].map({0: 'Good', 1: 'Bad'}),\n",
        "    'CRB Score/Result': df['CRB Class'].values if 'CRB Class' in df.columns else 'N/A',\n",
        "    'Business Quality': df['Business_Quality_Score'].round(2).values,\n",
        "    'Financial Resilience':  df['Financial_Resilience_Score'].round(2).values,\n",
        "    'Stability': df['Stability_Score'].round(2).values,\n",
        "    'Expense Mgmt': df['Expense_Management_Score'].round(2).values\n",
        "})\n",
        "\n",
        "print(\"   ✓ Scorecard created\")\n",
        "\n",
        "# Display\n",
        "print(\"\\n\" + \"=\"*140)\n",
        "print(\"CUSTOMER SCORECARD - ALL 559 CUSTOMERS\")\n",
        "print(\"=\"*140)\n",
        "print(\"\\nFirst 20 rows:\")\n",
        "print(scorecard.head(20).to_string(index=False))\n",
        "\n",
        "print(f\"\\n\\nLast 10 rows:\")\n",
        "print(scorecard.tail(10).to_string(index=False))\n",
        "\n",
        "# Save (with directory creation)\n",
        "scorecard.to_csv('models/complete_scorecard_559_customers.csv', index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*140)\n",
        "print(\"✓ COMPLETE SCORECARD SAVED!\")\n",
        "print(f\"  File:  models/complete_scorecard_559_customers.csv\")\n",
        "print(f\"  Total Customers: {len(scorecard)}\")\n",
        "print(\"=\"*140)\n",
        "\n",
        "# Summary\n",
        "print(\"\\n📊 SUMMARY STATISTICS:\")\n",
        "print(\"-\"*80)\n",
        "print(f\"Total Customers:          {len(scorecard)}\")\n",
        "print(f\"Good Customers:           {(scorecard['Good or Bad?'] == 'Good').sum()} ({(scorecard['Good or Bad?'] == 'Good').sum()/len(scorecard)*100:.1f}%)\")\n",
        "print(f\"Bad Customers:           {(scorecard['Good or Bad?'] == 'Bad').sum()} ({(scorecard['Good or Bad?'] == 'Bad').sum()/len(scorecard)*100:.1f}%)\")\n",
        "print(f\"\\nAverage Default Probability:\")\n",
        "print(f\"  XGBoost:                 {scorecard['XGBoost V2 Feature Set A']. mean():.2f}%\")\n",
        "print(f\"  LightGBM:              {scorecard['LightGBM V2 Feature Set C']. mean():.2f}%\")\n",
        "print(f\"\\nAverage Composite Scores:\")\n",
        "print(f\"  Financial Resilience:   {scorecard['Financial Resilience'].mean():.2f}\")\n",
        "print(f\"  Business Quality:      {scorecard['Business Quality'].mean():.2f}\")\n",
        "print(f\"  Stability:               {scorecard['Stability'].mean():.2f}\")\n",
        "print(f\"  Expense Management:    {scorecard['Expense Mgmt'].mean():.2f}\")\n",
        "print(\"-\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "42ASnzN_lNdL",
        "outputId": "41293713-43ff-429f-e2d5-954534c1d3d5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating customer scorecard for all 559 customers...\n",
            "================================================================================\n",
            "✓ Directories created\n",
            "\n",
            "1. Training XGBoost V2 Feature Set A...\n",
            "   ✓ XGBoost trained\n",
            "\n",
            "2. Training LightGBM V2 Feature Set C...\n",
            "   ✓ LightGBM trained\n",
            "\n",
            "3. Preparing all 559 customers for scoring...\n",
            "   ✓ All customers prepared\n",
            "\n",
            "4. Generating predictions for all 559 customers...\n",
            "   ✓ Predictions complete\n",
            "\n",
            "5. Building scorecard table...\n",
            "   ✓ Scorecard created\n",
            "\n",
            "============================================================================================================================================\n",
            "CUSTOMER SCORECARD - ALL 559 CUSTOMERS\n",
            "============================================================================================================================================\n",
            "\n",
            "First 20 rows:\n",
            " ID  XGBoost V2 Feature Set A  LightGBM V2 Feature Set C Good or Bad? CRB Score/Result  Business Quality  Financial Resilience  Stability  Expense Mgmt\n",
            "  1                 75.209999                      70.08          Bad    Unrated / New              78.5                  57.0       66.5          53.0\n",
            "  2                 16.920000                      13.87         Good    Unrated / New              78.5                  57.0       86.5          53.0\n",
            "  3                 69.720001                      19.24         Good    Unrated / New              56.0                  72.0       66.5          78.0\n",
            "  4                 10.790000                      10.99         Good    Unrated / New              56.0                  72.0       66.5          95.5\n",
            "  5                 14.680000                       6.22         Good    Unrated / New              60.5                  57.0       66.5          70.5\n",
            "  6                 69.720001                      79.47          Bad    Unrated / New              56.0                  72.0       66.5          78.0\n",
            "  7                 65.760002                      15.39         Good    Unrated / New              56.0                  72.0       86.5          95.5\n",
            "  8                 54.560001                       9.16         Good    Unrated / New              56.0                  57.0       66.5          53.0\n",
            "  9                 47.910000                      33.25          Bad    Unrated / New              56.0                  54.0       66.5          48.0\n",
            " 10                 42.230000                      10.04         Good    Unrated / New              56.0                  57.0       82.5          53.0\n",
            " 11                 54.560001                       9.16         Good    Unrated / New              56.0                  57.0       66.5          53.0\n",
            " 12                 20.400000                      25.57         Good    Unrated / New              60.5                  72.0       66.5          95.5\n",
            " 13                 54.560001                      10.57         Good    Unrated / New              56.0                  57.0       66.5          53.0\n",
            " 14                 20.930000                       4.69         Good    Unrated / New              56.0                  63.0       66.5          63.0\n",
            " 15                 80.180000                      59.32          Bad    Unrated / New              78.5                  72.0       66.5          78.0\n",
            " 16                 20.930000                       4.69         Good    Unrated / New              56.0                  63.0       66.5          63.0\n",
            " 17                  8.230000                       7.05         Good    Unrated / New              60.5                  63.0       86.5          63.0\n",
            " 18                 27.629999                       6.57         Good    Unrated / New              56.0                  57.0       86.5          53.0\n",
            " 19                  2.920000                       3.27         Good    Unrated / New              60.5                  56.0       89.5          65.5\n",
            " 20                 55.810001                      14.48         Good    Unrated / New              87.5                  69.0       63.5          57.5\n",
            "\n",
            "\n",
            "Last 10 rows:\n",
            " ID  XGBoost V2 Feature Set A  LightGBM V2 Feature Set C Good or Bad? CRB Score/Result  Business Quality  Financial Resilience  Stability  Expense Mgmt\n",
            "550                 26.040001                      12.32         Good    Unrated / New              65.0                  75.0       63.5          67.5\n",
            "551                  6.040000                      11.12         Good    Unrated / New              72.5                  59.5       79.5          75.0\n",
            "552                 29.879999                      76.76         Good    Unrated / New              87.5                  41.5       83.5          52.5\n",
            "553                  7.570000                      29.40         Good    Unrated / New              72.5                  79.0       75.5          67.5\n",
            "554                 63.950001                      26.01         Good    Unrated / New              72.5                  69.0       63.5          67.5\n",
            "555                 16.629999                       1.96         Good    Unrated / New              54.5                  60.5       95.5          60.0\n",
            "556                 13.210000                      11.92         Good    Unrated / New              69.5                  69.0       83.5          57.5\n",
            "557                 48.279999                      29.31         Good    Unrated / New              87.5                  50.5       79.5          67.5\n",
            "558                 63.430000                      66.73          Bad    Unrated / New              54.5                  44.5       63.5          50.0\n",
            "559                  6.040000                      36.64         Good    Unrated / New              72.5                  59.5       79.5          75.0\n",
            "\n",
            "============================================================================================================================================\n",
            "✓ COMPLETE SCORECARD SAVED!\n",
            "  File:  models/complete_scorecard_559_customers.csv\n",
            "  Total Customers: 559\n",
            "============================================================================================================================================\n",
            "\n",
            "📊 SUMMARY STATISTICS:\n",
            "--------------------------------------------------------------------------------\n",
            "Total Customers:          559\n",
            "Good Customers:           343 (61.4%)\n",
            "Bad Customers:           216 (38.6%)\n",
            "\n",
            "Average Default Probability:\n",
            "  XGBoost:                 40.86%\n",
            "  LightGBM:              40.35%\n",
            "\n",
            "Average Composite Scores:\n",
            "  Financial Resilience:   61.25\n",
            "  Business Quality:      63.07\n",
            "  Stability:               74.64\n",
            "  Expense Management:    67.45\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the scorecard\n",
        "from google.colab import files\n",
        "files.download('models/complete_scorecard_559_customers.csv')\n",
        "\n",
        "print(\"\\n🎉 SUCCESS!   Your scorecard is ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "gC7S30lUlp7D",
        "outputId": "9bf17fdc-4577-45c3-969a-0b6e9d31e6f6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_12a8619c-6ba7-4caa-823d-e1e8cb38d6b7\", \"complete_scorecard_559_customers.csv\", 32755)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎉 SUCCESS!   Your scorecard is ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check your actual dataset size\n",
        "print(\"=\"*80)\n",
        "print(\"DATASET INFORMATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Total rows (customers): {len(df)}\")\n",
        "print(f\"Total columns (features): {len(df.columns)}\")\n",
        "print(f\"\\nTarget variable distribution:\")\n",
        "print(df[TARGET].value_counts())\n",
        "print(f\"\\nDefault rate: {df[TARGET].mean() * 100:.2f}%\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZhywJXyluLg",
        "outputId": "40b8f2aa-2d91-4262-e257-1b41e7cb650b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "DATASET INFORMATION\n",
            "================================================================================\n",
            "Total rows (customers): 559\n",
            "Total columns (features): 101\n",
            "\n",
            "Target variable distribution:\n",
            "Defaulted\n",
            "0    343\n",
            "1    216\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Default rate: 38.64%\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}